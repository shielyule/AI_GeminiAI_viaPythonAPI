{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857ad0d9-9c6e-4df9-acc6-7dde753d78f6",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.pieriantraining.com/\" ><img src=\"../PTCenteredPurple.png\" alt=\"Pierian Training Logo\" /></a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc0f48-cb44-4a2a-80d2-aa22449b31af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating Text\n",
    "\n",
    "Let's explore how to send a simple prompt and get Gemini to return text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8091526-eb71-410b-b97a-d6fd5b234a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e4123d-9682-461c-b456-1df1e35ec182",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['GEMINI_API_KEY'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcee58c5-e7a2-41f8-89d4-2b52b8b2ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b0849d-7386-47bd-989e-70c5ae5d663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca6162-80d8-4fef-bf13-6ec0fd64a1a6",
   "metadata": {},
   "source": [
    "# `gemini-pro` Text and Single Response API Call\n",
    "To start, let's ask a simple question. First, we'll create a `GenerativeModel` object, which tells Gemini which model to use. For text-based questions and answers, as well as chats, we'll use **gemini-pro**, a model designed for general *text-based* tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cebe1227-52ec-4a63-8f26-22f420188026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fed70d-a981-4357-a204-3377dce564c1",
   "metadata": {},
   "source": [
    "To communicate our prompts to Gemini's backend, we'll utilize the `model.generate_content('prompt')` function. This function handles diverse prompt types and use cases, such as text-only, text+image, and chatbot interactions, depending on the model linked to it.\n",
    "\n",
    "You can find the full documentation of `model.generate_content()` [here](https://ai.google.dev/api/python/google/generativeai/GenerativeModel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55647806-1c4e-434a-ada4-c55727109c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the capital of the United States?\"\n",
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e44bdb-a6d6-44f1-a1fb-f30f5100bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.generativeai.types.generation_types.GenerateContentResponse"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73677210-6279-41ef-a870-adeb429ca236",
   "metadata": {},
   "source": [
    "In this case the result can be accessed via `reponse.text`. The status is stored within `response.prompt_feedback`.<br />\n",
    "If multiple responses have beed created you can inspect them using `response.candidates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7908d36-af84-4e7d-8e09-91955560e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c241b6c8-fae0-4397-a763-c07218855e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.prompt_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9824bec5-7f7a-4040-989c-28f41c330e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[index: 0\n",
      "content {\n",
      "  parts {\n",
      "    text: \"Washington, D.C.\"\n",
      "  }\n",
      "  role: \"model\"\n",
      "}\n",
      "finish_reason: STOP\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(response.candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf194ad-2552-4793-a63c-69eb6b6c2f37",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ddc9e-7a34-4b16-be8a-1a1b22ab4680",
   "metadata": {},
   "source": [
    "Let's try another, more creative prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7177b68-2598-4b40-a70b-4002f39c727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, listen up, let's talk about Claude Shannon, the OG of information theory\n",
      "A brilliant mind, a true visionary\n",
      "His work laid the foundation, for the digital revolution we see\n",
      "\n",
      "In the realm of communication, he was the pioneer\n",
      "Crafting mathematical tools, crystal clear\n",
      "From his groundbreaking ideas, a new era was born\n",
      "Information quantified, like never before\n",
      "\n",
      "He defined entropy, the measure of disorder\n",
      "The heart of uncertainty, like a hidden border\n",
      "Bits and Baud, symbols and signals, he explored\n",
      "Unveiled the secrets, of the code\n",
      "\n",
      "Through noisy channels, his insights did flow\n",
      "Error-correcting codes, letting data grow\n",
      "He showed us how to transmit, without distortion\n",
      "Preserving information, in perfect proportion\n",
      "\n",
      "From cryptography to data compression, his impact was vast\n",
      "Shannon's theorems, like stars in the night, contrast\n",
      "The father of modern communication, his legacy profound\n",
      "In circuits and algorithms, his genius astounds\n",
      "\n",
      "Like a codebreaker, he unraveled the puzzle\n",
      "Of information's essence, no longer a muddle\n",
      "He tamed the chaos, brought order to the game\n",
      "A pioneer of cyberspace, forever his name\n",
      "\n",
      "In the symphony of bits, his melody resounds\n",
      "The maestro of information, breaking all bounds\n",
      "His theories, like symphonies, elegant and deep\n",
      "A timeless masterpiece, forever we'll keep\n",
      "\n",
      "So let's raise a glass, to Claude Shannon, the great\n",
      "Whose mind illuminated, like a celestial gate\n",
      "His legacy lives on, in the digital age\n",
      "A true visionary, on history's stage\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a rap about Claude Shannon with lots of esoteric references, but make sure it rhymes\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e082146-eb14-4108-bffa-c05476db63c7",
   "metadata": {},
   "source": [
    "----\n",
    "Remember to save time, you could make this a function yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec6dc89-a720-4767-8c6e-f4b33a8d9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
